# 《Can Segmentation Models Be Trained with Fully Synthetically Generated Data》笔记
[分割模型能否用完全合成的数据进行训练?论文地址](https://arxiv.org/abs/2209.08256)

## 摘要
因为医学本身的特性，医学影像分割模型一般需要足够大且变一下足够的数据集。由于现实限制，常常无法获得充分数据，许多该领域工作者采用人工增加数据的方式，避免医学影像分割陷入过拟合，保证模型通用性。本论文==提出了brainSPADE，这是一个将基于合成扩散的标签生成器与语义图像生成器相结合的模型，可以按需产生完全合成的大脑标签，然后生成相应的任意引导式的图像。==

## 背景
CNN对于代替人工进行医学图像分析上效果显著，但是需要大量且异质性的病理学训练数据来达到比较好的拟合效果。然而病理学图像数据集获取需要的设备昂贵且大多非公开获取难度大，即使能够获得的数据集大多也缺少标签且只能针对特定的任务。如果有一个模型可以生成任意对比度的病理学图片以及相关联的标签，可以让图像分割的研究更加民主化以及提高模型的准确度和普及性。

脑部磁共振成像(MRI)数据集是异质性的，因为往往来自不同图像采集协议，并被部分标记且不同数据集之间严重缺乏标签一致性。为解决该问题有两种方案：
[多任务学习技术](https://zhuanlan.zhihu.com/p/348873723)
[Domain Adaptation](https://zhuanlan.zhihu.com/p/50710267)
- 使用领域自适应（DA）和多任务学习技术来创建对小的不完整的数据集具有鲁棒性的模型。
- 通过在单个图像上应用简单的转换或通过沿着相关的变化方向建立数据分布模型来增加数据。（GAN,VAE等等）

之前已经有使用条件生成模型增强MRI任务数据的应用但数据集中包含原始数据，本片文章使用完全由brainSPADE模型生成的图片进行分割任务的训练。

## 数据集和方法
[医学影像分割入门、MRI、t1、t2等序列概念](https://zhuanlan.zhihu.com/p/164637783)
图像数据采用T1加权以及FLAIR技术处理的来自几个数据集的图像，具体数据集的构建见论文。

### 设计方法
完整的模型，包括标签和图像生成器。
![](论文笔记/Can%20Segmentation%20Models%20Be%20Trained%20with%20Fully%20Synthetically%20Generated%20Data/asset/模型.png)
#### 标签生成器
输入分段包含了病人的形态学特征，因此信息受保护，需要病人的同意才能共享。为了解决GAN在标签图生成方面的内在限制，我们选择应用[潜伏扩散模型(LDMs)](https://zhuanlan.zhihu.com/p/582693939)。首先，训练一个特殊包含两个下采样和一个48x64x3潜在空间的VAE，优化损失函数为$L_{VAE}=D_{KLD}(E(l)||\mathcal{N}(0,I)+L_{perc}(l,\hat{l})+L_{adv}(D(l),D(\hat{l}))+L_{l1}(\hat{l},l))$
其中$l$为输入的真实分割图，$\hat{l}$为重建的概率部分体积分割图，$KLD$为KL散度，$L_{perc}$为感知性损失，$L_{adv}$为对抗性损失，通过D来进行计算。$L_{l1}$为L1正则。
由于一个空间VAE潜在表征有语义背景，因此不能从高斯分布中取样生成。因此，通过LDM模型对该潜在的表征中的一个实例进行采样和去噪然后用VAE进行解码。LDM模型是1000个时间步长条件下的UNet，我们使用固定的方差和重新参数化的方法来预测每个时间步长的附加噪声。
使用L1损失优化模型。在健康和受肿瘤影响的语义标签片上训练了两种不同的LDM模型。

#### 图像生成器
SPACE是从语义图中生成高质量图像的模型，该网络是VAE-GAN，其中编码器产生一个输入风格图像的潜在空间呈现，由解码器使用，和语义图一起创建一个输出图像。语义图通过特殊的归一化块进行输入，在不同上采样水平上将所需的内容打印在输出上。使用原始损失来训练SPACE——基于Patch-GAN判别器的对抗性Hinge损失、感知损失、KLD损失和正则器特征匹配损失。这些损失对应与和输入语义图和和输入风格图像相匹配的图像。
SPACE模型存在一下缺陷：
1. 编码风格的潜空间只用KLD损失进行优化，没有具体的聚类执行。在我们的方案中，风格图像是MRI对比度，将组织的外观与它的磁特性联系起来，因此需要确保潜空间是基于对比度而不是切片数量等方面进行聚类的。
2. SPADE被设计为接受分类分割。然而，以前的的工作表明，部分体积图，即把属于每一类的概率联系起来。属于每一类的概率与每个像素相关联，从而在输出图像上产生更精细的细节。输出图像的细节。
3. 如前所述，SPADE被设计用来处理网络不同阶段的风格和内容。在网络的不同阶段。然而，原始训练过程使用 成对的语义图和图像来计算损失，因此不可能排除风格潜伏空间不包含一些关于风格的信息。排除风格潜伏空间不包含一些关于输出图像内容的信息。输出图像的内容。

**解决缺陷1：** 
首先，通过增加模式和数据集辨别损失$L_{mod,dat}$，通过使用一对前向过程通过在真实数据上预训练的数据集辨别器的生成图像来进行计算：
$L_{mod,dat}=\alpha_{mod}\times BCE(mod_{\hat{i}},mod_{i})+\alpha_{dat}\times BCE(dat_{\hat{i}},dat_i)$
BCE是二元交叉熵损失，mod和dat是$D_{mod,dat}$预测的模式数据集，$\hat{i}$是生成图像$i$是等效的真实图像。我们始终保持在整个训练过程中$\alpha_{mod}>\alpha_{dat}$。
其次，一个潜在空间对比学习损失被引入，$L_{contrastive}= cosim(E_s(i),E_s(T(i))$,cosim为余弦相似度指数，$E_s$为风格编码器，$i$为输入风格图像$T$为一个通过Medical Open Network实现的随机的仿射变换。
**解决缺陷2：**
用概率部分体积图代替分类标签解决的，我们也用概率部分体积图来训练标签生成器。
**解决缺陷3：**
通过使用同一体积的不同脑切片来作为风格图像和语义图，强制分离风格和内容生成管道。
### 模型选择
对于分割任务，我们使用训练过的2D nnU-net进行训练直到收敛。

## 实验结果
测试完成合成的数据集是否可以用来训练分割模型，我们提出三个实验在合成数据上训练健康组织分割、非分布式健康组织分割和肿瘤分割。
### 我们能否学会使用合成数据对健康区域进行分类？
#### 实验设置
在T1图像上训练两个模型来切割三个组织，CSF,GM,WM。
$R_{iod}$模型，在7008对来自SABER的数据切片上进行训练。
$S_{iod}$模型，在20000张合成局部体积图生成图像上进行训练。

模型通过来自SABRE的25组保留数据进行测试，对2D聚合nnUnet进行Dice分数计算。
#### 结论
我们用双侧t检验来比较结果。尽管对于所有的区域来说，$R_{iod}$的性能明显更好（P值<0.05），但Siod获得的Dice分数已经与过去工作中取得的性能相当。
### 合成生成模型能否解决分布区外的分割问题？
#### 实验设置
作为上一个实验的扩展，探索了我们的模型在处理分布外（OoD）风格图像时的潜力。
进行了一个近距离oD实验（n-oD）和一个远距离oD实验（f-oD），使用一组来自25个T1 ABIDE卷的切片（代表n-oD）和一组25个OASIS FLAIR卷（代表f-oD）作为测试目标数据集。$R_{iod}$和$S_{iod}$ 都在这些数据集上进行了测试。我们还在来自目标n-oD和f-oD分布的5个配对容积的580个切片上训练了模型$R_{n-ood}$和$R_{f-ood}$，作为参考，并在20000个brainSPADE生成的图像上训练了$S_{n-ood}$和$S_{n-ood}$模型，在推理过程中使用来自目标n-oD和f-oD分布的未配对图像的样式。
#### 实验结果
$S_{iod}$和$R_{iod}$在对n-OoD和f-OoD数据进行测试时都出现了性能下降。而$S_{n-ood}$和$S_{f-ood}$则明显更好（P值<0.0001）,这说明brainSPADE在领域自适应上也有潜力。
### 从合成数据中分离病症
#### 实验设置
在本实验中训练模型来分割肿瘤细胞。训练三个模型，在5对来自目标集合样本的1064个切片下训练的$R_{les}$，在20000个来自brainSPADE中采样的切片下训练的$S_{les}$，$H_{les}$的样本中包含了$R_{les}$和$S_{les}$的训练样本。
模型结果被三十卷来自目标数据集的数据进行测试。
#### 实验结果
混合模型$H_{les}$取得效果最好，Recall明显高于S和R模型。